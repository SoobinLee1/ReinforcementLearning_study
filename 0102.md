#Markov Decision Process

###강화학습은 **순차적 의사결정 문제**를 푸는 과정

###순차적 의사결정 문제
* Markov Process
  - MP≡(S,P)    S={s0,s1,s2,...} P: 전이확률행렬 ( Pss' = s에서 s'으로 전이할 확률, Pss' = P(s_t+1=s' | s_t=s) )
  - Markov property : 미래(s_t+1)는 오직 현재(s_t)에 의해 결정된다.

* Markov Reward Process
  - MRP ≡ (S,P,R,𝜸)     R: E[R_t|S_t=s]  𝜸:감쇠인자(𝟎≤𝜸<𝟏)->Return G에 사용, 𝜸이 작으면 일종의 greedy
  - Return G = 𝑅_(𝑡+1)+𝜸𝑅_(𝑡+2)+𝜸^2 𝑅_(𝑡+3)+...
  - state value function
     𝑣(𝑠)=𝔼[𝐺_𝑡 |𝑆_𝑡=𝑠]
     s에서 시작하는 에피소드를 샘플링하여 기댓값 산출

* Markov Decision Process
  - MDP ≡(𝑺,𝑨,𝑷,𝑹,𝜸)
  - policy function  𝛱(𝑎│𝑠)=ℙ[𝑨_𝒕=𝒂|𝑆_𝑡=𝑠]
  - state value function  𝑣_𝛱 (𝑠)=𝔼[𝐺_𝑡 |𝑆_𝑡=𝑠] : s에서 끝까지 𝛱를 따라갔을 때 얻는 리턴의 기댓값

* Further more
  - Prediction : 𝛱가 주어졌을 때, 𝑣_𝛱 (𝑠) 평가
  - Control : 최적의 정책 𝛱^∗ 찾기